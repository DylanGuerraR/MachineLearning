# Proyecto de An√°lisis y Carga de Leads en BigQuery

Este proyecto realiza la carga, limpieza y an√°lisis de datos de leads usando Google Cloud Platform (GCP). Se compone de varios scripts en Python que automatizan diferentes etapas del proceso ETL (Extracci√≥n, Transformaci√≥n y Carga), as√≠ como un notebook que contiene el an√°lisis y modelado de datos usando t√©cnicas de Machine Learning.

## üöÄ Descripci√≥n General

El flujo de trabajo del proyecto se divide en tres partes principales:

1. **Carga de Datos a BigQuery** (`conexion_gcp.py`):
   - Sube un archivo CSV local a BigQuery.
   - Automatiza la conexi√≥n a GCP usando credenciales de servicio.

2. **Limpieza y Transformaci√≥n de Datos** (`sql_limpieza.py`):
   - Realiza consultas SQL para depurar y transformar datos directamente en BigQuery.
   - Elimina columnas innecesarias, maneja valores nulos, elimina duplicados y agrega columnas derivadas.

3. **An√°lisis y Modelado** (`analisis_datos_leads.ipynb`):
   - Descarga los datos procesados desde BigQuery para realizar an√°lisis exploratorio.
   - Aplica modelos de Machine Learning (XGBoost y Random Forest) para predicci√≥n y an√°lisis de leads.

---

## üìÇ Estructura del Repositorio
```
|-- conexion_gcp.py                # Carga de datos desde CSV a BigQuery
|-- sql_limpieza.py                # Consultas SQL para limpiar y transformar datos
|-- analisis_datos_leads.ipynb     # An√°lisis exploratorio y modelado de datos (ML)
|-- requirements.txt               # Librer√≠as necesarias
|-- README.md                      # Documentaci√≥n del proyecto
```

---

## üìÑ Detalle de Archivos

### 1. `conexion_gcp.py`  
- **Funci√≥n:** Subir archivos CSV a BigQuery.  
- **Caracter√≠sticas:**
  - Autodetecta el esquema del archivo CSV.
  - Configura la conexi√≥n con BigQuery usando credenciales de servicio.
  - Carga datos en la tabla `table_lead_tfg` dentro del dataset `leads`.

### 2. `sql_limpieza.py`  
- **Funci√≥n:** Realiza limpieza y transformaci√≥n de datos en BigQuery mediante consultas SQL.  
- **Consultas:**
  1. Elimina columnas innecesarias.
  2. Maneja valores nulos reemplaz√°ndolos con valores por defecto.
  3. Elimina duplicados.
  4. Agrega nuevas columnas calculadas.
  5. Filtra datos irrelevantes.

- **Resultado Final:** Crea la tabla `cleaned_leads` que contiene datos listos para el an√°lisis.

### 3. `analisis_datos_leads.ipynb`  
- **Funci√≥n:** Descarga datos desde BigQuery y realiza an√°lisis exploratorio.  
- **Modelo:** Usa modelos de Machine Learning (XGBoost y Random Forest) para realizar predicciones y an√°lisis de los leads.
- **Automatizaci√≥n:**
  - Descarga autom√°tica de credenciales desde GCS.
  - Inicializaci√≥n autom√°tica del cliente de BigQuery.

---

## üîß Instalaci√≥n y Configuraci√≥n

### 1. Clonar el Repositorio
```bash
git clone <URL_DEL_REPOSITORIO>
cd <NOMBRE_DEL_REPOSITORIO>
```

### 2. Crear un Entorno Virtual (Opcional pero Recomendado)
```bash
python -m venv gauss-entorno
source gauss-entorno/bin/activate  # Linux/Mac
```

### 3. Instalar Dependencias
```bash
pip install -r requirements.txt
```

---

## üõ†Ô∏è Requisitos

### Archivo `requirements.txt`
```text
google-cloud-storage
google-cloud-bigquery
pandas
numpy
matplotlib
scikit-learn
seaborn
xgboost
``` 

---

## ‚ú® Ejecuci√≥n de los Scripts

### 1. Cargar Datos desde CSV a BigQuery
```bash
python conexion_gcp.py
```

### 2. Realizar Limpieza y Transformaci√≥n de Datos
```bash
python sql_limpieza.py
```

### 3. An√°lisis y Modelado en el Notebook
Abrir `analisis_datos_leads.ipynb` y ejecutar las celdas en orden.

---

## ‚öôÔ∏è Automatizaci√≥n de Credenciales en el Notebook
El notebook est√° configurado para descargar credenciales autom√°ticamente desde Google Cloud Storage (GCS) y autenticar el cliente de BigQuery. No es necesario realizar configuraciones adicionales.

---

## üö® Posibles Errores y Soluciones

1. **Error de permisos (403 Forbidden):**  
   - Aseg√∫rate de que la cuenta de servicio tenga permisos de `BigQuery Admin` y `Storage Object Viewer`.
   - Agregar permisos:  
   ```bash
   gcloud projects add-iam-policy-binding future-loader-433707-h4 \
     --member="serviceAccount:tfg-service-account@future-loader-433707-h4.iam.gserviceaccount.com" \
     --role="roles/bigquery.admin"
   ```

2. **Credenciales no encontradas:**  
   - Si el archivo de credenciales no existe, aseg√∫rate de que el bucket `tfg_credencial` tenga acceso p√∫blico o de que la cuenta tenga permisos adecuados para descargar el archivo.  

   ```bash
   gcloud storage buckets add-iam-policy-binding gs://tfg_credencial \
     --member="allUsers" \
     --role="roles/storage.objectViewer"
   ```

---

## üìà Resultados Esperados
- **Tablas en BigQuery:**
  - `leads.table_lead_tfg`: Datos brutos cargados desde CSV.
  - `leads.cleaned_leads`: Datos limpios y listos para an√°lisis.
- **Modelos de Machine Learning:**
  - Predicciones de conversi√≥n de leads usando Random Forest y XGBoost.
- **Visualizaciones:**
  - Gr√°ficos de distribuci√≥n, correlaci√≥n y an√°lisis exploratorio de datos (EDA).

---

## üöÄ Contribuciones y Contacto
Si deseas contribuir o tienes alguna pregunta, no dudes en enviar un Pull Request o contactar al autor del proyecto.

